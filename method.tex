\chapter{Method}\label{cha:meth}
In this chapter the methodology used to perform the tasks given above in \sectionref{sec:goals}.
\newpage
\section{Validation of smearing functions}
Find more information in my presentation. also mention no pile-up dependence of leptons.
For the proposed upgrade of the LHC.

The validation was done for \textbf{what MCdata? and validated for which pile-up?}

\subsection{Smearing}
One might assume that using a Monte Carlo simulation it would be easy to model and simulate the whole process, from collision to detection and reconstruction in the upgraded LHC. It is possible, but it requires a lot of computing power. Instead one can use one simulation and a mathematical model to calculate the estimated response in the detector. This was validated and used in this thesis to be able to create the data needed for further analysis. 

This was done by using a Monte Carlo simulation of a proton-proton collision, then applying code, that was developed using previous studies \citep{ATL-PHYS-PUB-2013-004} , to simulate the effect that pile-up would have on the signals that come from the detectors and the reconstruction of these. \textbf{Code from where?}

The code uses the experimental data from the previous studies to smear the reconstructed energy and momenta; It does not however alter the direction of the momenta. Other experimental data was used and shows that only jets and $E^{miss}_T$ are affected by pile-up. That this is true can be shown from \textbf{figures and references from nonpileupdep.txt presentation!}. The smearing functions should be given!

\subsection{Validation}
To validate the code comparisons were made with \citep{ATL-PHYS-PUB-2013-004}. 

Also include the following so that readers will understand the smearing functions.
\begin{eqnarray}
a\oplus b = a^2 + b^2 \\
a\oplus b\oplus c = a^2+b^2+c^2 
\end{eqnarray}

Parametrization used according to the paper \citep{ATL-PHYS-PUB-2013-004}. What results and what did I get/say in my presentation? Use that in results Perhaps even write something better than the original that can be used to explain this again.

Remember for the discussion to mention different types of rms, relative or absolute. and the problem which occurred with this and the papers faults.

\section{Evaluating dark matter signals}
The main goal of the thesis is to investigate if certain dark matter signals can be detected after the high luminosity upgrade. One immediate worry is that the background will be large in comparison to the signal, thus making it undetectable. 

The following signals models have been used:
\textbf{Here only the opperators should be explained, or different models. The names and the MC here or in appendix?}
Each of these has been evaluated in different signal regions and the detectability has been evaluated using a statistical P-value. This process has been performed at different pile-up values. 

\textbf{What background existed? How was it simulated in MC? Should that be here or in appendix?}


\subsection{Signal to background ratio}
What I am doing now, looking at what signal? What are the different background processes? What and why was the weight used?

Signals should be explained somewhat in the introduction.



Look at presentation, is it worth bringing up the first signal regions when the data has already been filtered? Should that be here?
 
\subsection{Selection criteria}
What criteria were used and more importantly why? It is quite important that you can explain why this was used.

\subsection{Comparing with published papers} 	
To verify that the background data was correct it was compared with \citep{ATLAS-CONF-2012-147}, in which the luminosity if 10 fb$^{-1}$ and thus the expected values from the paper scaled up with a factor 100. \textbf{Also, somewhat unexpectedly is that the difference in center of mass energy required the cross-sections to be lowered than compared with the upgrade.} The signal region used in the article were the following:
\begin{itemize}
\item Jet veto, require no more than 2 jets with $p_T > 30 GeV$ and $|\eta| < 4.5$
\item Lepton veto, no electron or muon, leading jet with $|\eta| < 2.0$ and $\Delta \phi (jet, E_T^{miss})>0.5$ (second-leading jet)
\item Leading jet with $p_T > 500 GeV$ and $E_T^{miss}>500 GeV$
\end{itemize}
The article has several different signal regions, the difference is the last item, unfortunately since the simulated events are already filtered before the analysis only one of the regions could be used.
\begin{table}[ht]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Process & Simulated events & Expected events (Scaled to 1000 fb$^{-1}$) \\ \hline
Z$\rightarrow\nu\nu$&27675.1&27000 \\
W$\rightarrow\tau\nu$&6506.09&3900 \\
W$\rightarrow e\nu$&1660.06&1600 \\
W$\rightarrow\mu\nu$&2048.77&4200 \\
Total background&37890&36700 \\ \hline
\end{tabular}
\caption{Comparison of the simulated and from \citep{ATLAS-CONF-2012-147} expected events}
\label{tab:Compare1}
\end{center}
\end{table}

In \tableref{tab:Compare1} a comparison has been made. It can be seen that the simulated events and expected events coincide on all accounts apart from W$\rightarrow\tau\nu$, W$\rightarrow\mu\nu$ and thus the total as well. \textbf{This can be explained by better separation of $\mu$,$\tau$ and missing energy.} 

\subsection{Figures of merit}
P-value, see more in Majas phd thesis when completed.
\section{Other selection criteria and observables}
\section{Mitigating the effect}